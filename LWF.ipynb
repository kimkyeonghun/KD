{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /home/kkh/anaconda3\r\n",
      "BertT                    /home/kkh/anaconda3/envs/BertT\r\n",
      "KD                    *  /home/kkh/anaconda3/envs/KD\r\n",
      "msa                      /home/kkh/anaconda3/envs/msa\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.5 (default, Oct 25 2019, 15:51:11) \n",
      "[GCC 7.3.0]\n",
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import keras as k\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "print(sys.version)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = datasets.cifar10.load_data()\n",
    "datagen = ImageDataGenerator(rotation_range = 15,horizontal_flip = True, vertical_flip= True, width_shift_range= 0.1, height_shift_range= 0.1, zoom_range = 0.1)\n",
    "datagen.fit(train_x)\n",
    "train_x=train_x.astype(\"float32\")  \n",
    "test_x=test_x.astype(\"float32\")\n",
    "mean=np.mean(train_x)\n",
    "std=np.std(train_x)\n",
    "test_x=(test_x-mean)/std\n",
    "train_x=(train_x-mean)/std\n",
    "\n",
    "# labels\n",
    "num_classes=10\n",
    "train_y = k.utils.to_categorical(train_y, num_classes)\n",
    "test_y = k.utils.to_categorical(test_y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import keras as k\n",
    "trainX = []\n",
    "trainY = []\n",
    "train_path = './downsized/train/'\n",
    "train = os.listdir(train_path)\n",
    "for i in range(len(train)):\n",
    "    files = sorted(os.listdir(train_path+train[0]))\n",
    "    for j in range(20):\n",
    "        img = cv2.imread(train_path+train[i]+'/'+files[j])\n",
    "        img = cv2.resize(img,dsize=(32,32))\n",
    "        trainX.append(img)\n",
    "        trainY.append(i)\n",
    "\n",
    "testX = []\n",
    "testY = []\n",
    "test_path = './downsized/test/'\n",
    "test = os.listdir(test_path)\n",
    "for i in range(len(test)):\n",
    "    files = sorted(os.listdir(test_path+test[0]))\n",
    "    for j in range(10):\n",
    "        img = cv2.imread(test_path+test[i]+'/'+files[j])\n",
    "        img = cv2.resize(img,dsize=(32,32))\n",
    "        testX.append(img)\n",
    "        testY.append(i)\n",
    "        \n",
    "        \n",
    "\n",
    "import numpy as np\n",
    "trainX = np.array(trainX).reshape(-1,32,32,3)\n",
    "testX = np.array(testX).reshape(-1,32,32,3)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 15,horizontal_flip = True, vertical_flip= True, width_shift_range= 0.1, height_shift_range= 0.1, zoom_range = 0.1)\n",
    "datagen.fit(trainX)\n",
    "trainX=trainX.astype(\"float32\")  \n",
    "testX=testX.astype(\"float32\")\n",
    "mean=np.mean(trainX)\n",
    "std=np.std(trainX)\n",
    "testX=(testX-mean)/std\n",
    "trainX=(trainX-mean)/std\n",
    "\n",
    "trainY = np.array(trainY)\n",
    "testY = np.array(testY)\n",
    "trainY = k.utils.to_categorical(trainY, 100)\n",
    "testY = k.utils.to_categorical(testY, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plotting helper function\n",
    "def plothist_acc(hist):\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting helper function\n",
    "def plothist_loss(hist):\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('teacher.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 34, 34, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,655,114\n",
      "Trainable params: 33,646,666\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Lambda, Activation\n",
    "oldmodel = keras.Model(model.input,model.layers[-1].output)\n",
    "oldmodel.trainable=False\n",
    "\n",
    "Temperature = 10\n",
    "\n",
    "T_layer = Lambda(lambda x:x/Temperature)(oldmodel.output)\n",
    "Softmax_layer = Activation('softmax')(T_layer)\n",
    "soften = keras.Model(model.input,Softmax_layer)\n",
    "\n",
    "soft_label = soften.predict(trainX)\n",
    "soft_label_test = soften.predict(testX)\n",
    "\n",
    "new_train_y = np.concatenate([trainY,soft_label],axis=1)\n",
    "new_test_y = np.concatenate([testY,soft_label_test],axis=1)\n",
    "\n",
    "DenseForNew = Dense(100,name='dense_10')(oldmodel.layers[-2].output)\n",
    "output_new = Activation('softmax')(DenseForNew)\n",
    "warmupModel = keras.Model(model.input,output_new)\n",
    "\n",
    "adam = Adam(learning_rate = 0.0001, beta_1=0.9, beta_2=0.999)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',patience=20,mode='auto',restore_best_weights=True)\n",
    "warmupModel.compile(optimizer= adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = warmupModel.fit(trainX,trainY,epochs=200,validation_data=(testX,testY),callbacks=[early_stopping],batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 34, 34, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,655,114\n",
      "Trainable params: 0\n",
      "Non-trainable params: 33,655,114\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "oldmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_y = np.concatenate([trainY,soft_label],axis=1)\n",
    "new_test_y = np.concatenate([testY,soft_label_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "DenseForNew = Dense(100,name='dense_10')(oldmodel.layers[-2].output)\n",
    "output_new = Activation('softmax')(DenseForNew)\n",
    "warmupModel = keras.Model(model.input,output_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 34, 34, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               409700    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 34,023,844\n",
      "Trainable params: 409,700\n",
      "Non-trainable params: 33,614,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "warmupModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 4s 2ms/sample - loss: 5.0337 - accuracy: 0.0090 - val_loss: 4.6642 - val_accuracy: 0.0080\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.9572 - accuracy: 0.0100 - val_loss: 4.6434 - val_accuracy: 0.0100\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.8768 - accuracy: 0.0125 - val_loss: 4.6275 - val_accuracy: 0.0080\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.8658 - accuracy: 0.0130 - val_loss: 4.6147 - val_accuracy: 0.0120\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.8290 - accuracy: 0.0125 - val_loss: 4.6039 - val_accuracy: 0.0140\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.8160 - accuracy: 0.0130 - val_loss: 4.5947 - val_accuracy: 0.0140\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.7742 - accuracy: 0.0215 - val_loss: 4.5860 - val_accuracy: 0.0160\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.8001 - accuracy: 0.0145 - val_loss: 4.5780 - val_accuracy: 0.0190\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.7773 - accuracy: 0.0160 - val_loss: 4.5713 - val_accuracy: 0.0160\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.7672 - accuracy: 0.0180 - val_loss: 4.5648 - val_accuracy: 0.0170\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.7345 - accuracy: 0.0190 - val_loss: 4.5592 - val_accuracy: 0.0190\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.7399 - accuracy: 0.0155 - val_loss: 4.5537 - val_accuracy: 0.0190\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.7211 - accuracy: 0.0135 - val_loss: 4.5477 - val_accuracy: 0.0200\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6925 - accuracy: 0.0235 - val_loss: 4.5438 - val_accuracy: 0.0210\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6962 - accuracy: 0.0175 - val_loss: 4.5392 - val_accuracy: 0.0230\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6732 - accuracy: 0.0235 - val_loss: 4.5353 - val_accuracy: 0.0290\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6654 - accuracy: 0.0190 - val_loss: 4.5317 - val_accuracy: 0.0290\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6625 - accuracy: 0.0190 - val_loss: 4.5278 - val_accuracy: 0.0280\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6637 - accuracy: 0.0190 - val_loss: 4.5246 - val_accuracy: 0.0300\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6367 - accuracy: 0.0250 - val_loss: 4.5218 - val_accuracy: 0.0330\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6704 - accuracy: 0.0200 - val_loss: 4.5183 - val_accuracy: 0.0320\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6161 - accuracy: 0.0220 - val_loss: 4.5154 - val_accuracy: 0.0300\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6155 - accuracy: 0.0275 - val_loss: 4.5129 - val_accuracy: 0.0280\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6174 - accuracy: 0.0210 - val_loss: 4.5098 - val_accuracy: 0.0280\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6210 - accuracy: 0.0265 - val_loss: 4.5071 - val_accuracy: 0.0290\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6127 - accuracy: 0.0305 - val_loss: 4.5042 - val_accuracy: 0.0300\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6050 - accuracy: 0.0310 - val_loss: 4.5017 - val_accuracy: 0.0320\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5927 - accuracy: 0.0215 - val_loss: 4.4995 - val_accuracy: 0.0310\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6165 - accuracy: 0.0240 - val_loss: 4.4973 - val_accuracy: 0.0330\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5676 - accuracy: 0.0265 - val_loss: 4.4954 - val_accuracy: 0.0340\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.6115 - accuracy: 0.0240 - val_loss: 4.4934 - val_accuracy: 0.0350\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5750 - accuracy: 0.0310 - val_loss: 4.4916 - val_accuracy: 0.0350\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5761 - accuracy: 0.0245 - val_loss: 4.4904 - val_accuracy: 0.0340\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5620 - accuracy: 0.0300 - val_loss: 4.4888 - val_accuracy: 0.0350\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5909 - accuracy: 0.0260 - val_loss: 4.4863 - val_accuracy: 0.0360\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5425 - accuracy: 0.0300 - val_loss: 4.4844 - val_accuracy: 0.0360\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5891 - accuracy: 0.0325 - val_loss: 4.4831 - val_accuracy: 0.0360\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5358 - accuracy: 0.0270 - val_loss: 4.4815 - val_accuracy: 0.0370\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5239 - accuracy: 0.0340 - val_loss: 4.4793 - val_accuracy: 0.0360\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5499 - accuracy: 0.0295 - val_loss: 4.4782 - val_accuracy: 0.0370\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5434 - accuracy: 0.0310 - val_loss: 4.4774 - val_accuracy: 0.0370\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5675 - accuracy: 0.0260 - val_loss: 4.4764 - val_accuracy: 0.0380\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5740 - accuracy: 0.0255 - val_loss: 4.4757 - val_accuracy: 0.0380\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5609 - accuracy: 0.0255 - val_loss: 4.4747 - val_accuracy: 0.0360\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5071 - accuracy: 0.0285 - val_loss: 4.4735 - val_accuracy: 0.0360\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5434 - accuracy: 0.0270 - val_loss: 4.4720 - val_accuracy: 0.0350\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5014 - accuracy: 0.0455 - val_loss: 4.4711 - val_accuracy: 0.0360\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5217 - accuracy: 0.0310 - val_loss: 4.4703 - val_accuracy: 0.0360\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5272 - accuracy: 0.0360 - val_loss: 4.4694 - val_accuracy: 0.0370\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5113 - accuracy: 0.0355 - val_loss: 4.4686 - val_accuracy: 0.0370\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.4798 - accuracy: 0.0250 - val_loss: 4.4677 - val_accuracy: 0.0350\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5191 - accuracy: 0.0285 - val_loss: 4.4669 - val_accuracy: 0.0380\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5167 - accuracy: 0.0280 - val_loss: 4.4658 - val_accuracy: 0.0360\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.4855 - accuracy: 0.0280 - val_loss: 4.4654 - val_accuracy: 0.0360\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5066 - accuracy: 0.0270 - val_loss: 4.4641 - val_accuracy: 0.0360\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.4911 - accuracy: 0.0385 - val_loss: 4.4636 - val_accuracy: 0.0350\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.5083 - accuracy: 0.0250 - val_loss: 4.4623 - val_accuracy: 0.0330\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.4956 - accuracy: 0.0330 - val_loss: 4.4621 - val_accuracy: 0.0330\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.4891 - accuracy: 0.0385 - val_loss: 4.4614 - val_accuracy: 0.0350\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.4777 - accuracy: 0.0370 - val_loss: 4.4605 - val_accuracy: 0.0330\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.4697 - accuracy: 0.0405 - val_loss: 4.4597 - val_accuracy: 0.0340\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 4.4696 - accuracy: 0.0340 - val_loss: 4.4589 - val_accuracy: 0.0340\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "adam = Adam(learning_rate = 0.00001, beta_1=0.9, beta_2=0.999)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',patience=20,mode='auto',restore_best_weights=True)\n",
    "warmupModel.compile(optimizer= adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = warmupModel.fit(trainX,trainY,epochs=200,validation_data=(testX,testY),callbacks=[early_stopping],batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmupModel.save('warmup.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Lambda, Activation,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "warmupModel = load_model('warmup.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "warmupModel.trainable = True\n",
    "old_output = Activation('softmax',name=\"old_activation\")(oldmodel.layers[-1].output)\n",
    "\n",
    "combined_layer = concatenate([warmupModel.output,old_output])\n",
    "combined_model = keras.Model(warmupModel.input,combined_layer)\n",
    "for layer in combined_model.layers:\n",
    "    if layer.name.startswith('conv2d'):\n",
    "        layer.kernel_regularizer = keras.regularizers.l2(0.0005)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n"
     ]
    }
   ],
   "source": [
    "for layer in combined_model.layers:\n",
    "    if layer.name.startswith('conv2d'):\n",
    "        layer.kernel_regularizer = keras.regularizers.l2(0.0005)\n",
    "        print(\"Clear!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 34, 34, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   1792        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 34, 34, 64)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   36928       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 16, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 18, 18, 64)   0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 128)  73856       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 18, 18, 128)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 128)  147584      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 10, 10, 128)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 256)    295168      zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 256)    1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 256)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 10, 10, 256)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 256)    590080      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 256)    1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 10, 10, 256)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 256)    590080      zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 6, 6, 256)    0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 512)    1180160     zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4, 4, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 6, 6, 512)    0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 512)    2359808     zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 4, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 6, 6, 512)    0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 512)    2359808     zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 4, 4, 512)    0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 2, 2, 512)    2359808     zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 512)    2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 2, 2, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 4, 4, 512)    0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 512)    2359808     zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2, 2, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 2, 2, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 4, 4, 512)    0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 512)    2359808     zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2, 2, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         2101248     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4096)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         16781312    dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 4096)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 100)          409700      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           40970       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "old_activation (Activation)     (None, 10)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 110)          0           activation_1[0][0]               \n",
      "                                                                 old_activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 34,064,814\n",
      "Trainable params: 34,015,396\n",
      "Non-trainable params: 49,418\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.losses import kullback_leibler_divergence as KLD_Loss, categorical_crossentropy as logloss\n",
    "\n",
    "def LWF_loss(y_true,y_pred,lambd=0.1,T=2):\n",
    "    y_true,y_true_lwf = y_true[:,:100],y_true[:,100:]\n",
    "    y_pred,y_pred_lwf = y_pred[:,:100],y_pred[:,100:]\n",
    "    # Classic cross-entropy (without temperature) hard target\n",
    "    new_loss = logloss(y_true,y_pred)\n",
    "    # KL-Divergence loss for softened output (with temperature) soft target Loss_Teacher\n",
    "    old_loss = KLD_Loss(y_true_lwf,y_pred_lwf)\n",
    "\n",
    "    return lambd*old_loss + new_loss\n",
    "\n",
    "def accuracy(y_true,y_pred):\n",
    "    return categorical_accuracy(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 5s 3ms/sample - loss: 4.5278 - accuracy: 0.0010 - val_loss: 4.4343 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.4414 - accuracy: 0.0025 - val_loss: 4.3822 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.4036 - accuracy: 0.0035 - val_loss: 4.3369 - val_accuracy: 0.0020\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.3902 - accuracy: 0.0035 - val_loss: 4.3035 - val_accuracy: 0.0020\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.3499 - accuracy: 0.0020 - val_loss: 4.2678 - val_accuracy: 0.0030\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.3057 - accuracy: 0.0035 - val_loss: 4.2342 - val_accuracy: 0.0060\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.2937 - accuracy: 0.0030 - val_loss: 4.2050 - val_accuracy: 0.0080\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.2714 - accuracy: 0.0050 - val_loss: 4.1770 - val_accuracy: 0.0090\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.2150 - accuracy: 0.0040 - val_loss: 4.1454 - val_accuracy: 0.0090\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.1951 - accuracy: 0.0065 - val_loss: 4.1197 - val_accuracy: 0.0090\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.1397 - accuracy: 0.0090 - val_loss: 4.0856 - val_accuracy: 0.0100\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.1350 - accuracy: 0.0095 - val_loss: 4.0705 - val_accuracy: 0.0130\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.1008 - accuracy: 0.0100 - val_loss: 4.0531 - val_accuracy: 0.0140\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.0404 - accuracy: 0.0185 - val_loss: 4.0240 - val_accuracy: 0.0160\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 4.0258 - accuracy: 0.0155 - val_loss: 3.9994 - val_accuracy: 0.0170\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.9904 - accuracy: 0.0190 - val_loss: 3.9786 - val_accuracy: 0.0190\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.9903 - accuracy: 0.0155 - val_loss: 3.9569 - val_accuracy: 0.0200\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.9372 - accuracy: 0.0215 - val_loss: 3.9354 - val_accuracy: 0.0210\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.9197 - accuracy: 0.0170 - val_loss: 3.9171 - val_accuracy: 0.0220\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.8582 - accuracy: 0.0205 - val_loss: 3.8892 - val_accuracy: 0.0240\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.8115 - accuracy: 0.0290 - val_loss: 3.8687 - val_accuracy: 0.0270\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.8129 - accuracy: 0.0310 - val_loss: 3.8489 - val_accuracy: 0.0260\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.7899 - accuracy: 0.0310 - val_loss: 3.8360 - val_accuracy: 0.0310\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.7626 - accuracy: 0.0315 - val_loss: 3.8340 - val_accuracy: 0.0330\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.7633 - accuracy: 0.0310 - val_loss: 3.8098 - val_accuracy: 0.0340\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.6862 - accuracy: 0.0415 - val_loss: 3.7869 - val_accuracy: 0.0410\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.6922 - accuracy: 0.0390 - val_loss: 3.7680 - val_accuracy: 0.0440\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.6496 - accuracy: 0.0415 - val_loss: 3.7547 - val_accuracy: 0.0450\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.6330 - accuracy: 0.0470 - val_loss: 3.7419 - val_accuracy: 0.0440\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.6199 - accuracy: 0.0545 - val_loss: 3.7368 - val_accuracy: 0.0490\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.5308 - accuracy: 0.0615 - val_loss: 3.7198 - val_accuracy: 0.0530\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.4820 - accuracy: 0.0605 - val_loss: 3.7042 - val_accuracy: 0.0600\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.4910 - accuracy: 0.0650 - val_loss: 3.6998 - val_accuracy: 0.0620\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.4559 - accuracy: 0.0625 - val_loss: 3.6917 - val_accuracy: 0.0650\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.4511 - accuracy: 0.0645 - val_loss: 3.6805 - val_accuracy: 0.0670\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.4057 - accuracy: 0.0885 - val_loss: 3.6665 - val_accuracy: 0.0760\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.4174 - accuracy: 0.0740 - val_loss: 3.6565 - val_accuracy: 0.0740\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.3561 - accuracy: 0.0910 - val_loss: 3.6468 - val_accuracy: 0.0780\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.3156 - accuracy: 0.0915 - val_loss: 3.6455 - val_accuracy: 0.0770\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.2859 - accuracy: 0.0985 - val_loss: 3.6409 - val_accuracy: 0.0830\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.2695 - accuracy: 0.1030 - val_loss: 3.6376 - val_accuracy: 0.0870\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.2708 - accuracy: 0.1010 - val_loss: 3.6100 - val_accuracy: 0.0910\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.2662 - accuracy: 0.1005 - val_loss: 3.6302 - val_accuracy: 0.0920\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.1988 - accuracy: 0.1145 - val_loss: 3.6374 - val_accuracy: 0.0890\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.1228 - accuracy: 0.1230 - val_loss: 3.6424 - val_accuracy: 0.0930\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.2008 - accuracy: 0.1240 - val_loss: 3.6232 - val_accuracy: 0.1030\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.1107 - accuracy: 0.1350 - val_loss: 3.6110 - val_accuracy: 0.1040\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.1011 - accuracy: 0.1320 - val_loss: 3.5929 - val_accuracy: 0.1100\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.0921 - accuracy: 0.1355 - val_loss: 3.5807 - val_accuracy: 0.1190\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 3.0509 - accuracy: 0.1410 - val_loss: 3.5956 - val_accuracy: 0.1190\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.9768 - accuracy: 0.1675 - val_loss: 3.5809 - val_accuracy: 0.1220\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.9797 - accuracy: 0.1700 - val_loss: 3.6040 - val_accuracy: 0.1260\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.9395 - accuracy: 0.1760 - val_loss: 3.5834 - val_accuracy: 0.1350\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.9538 - accuracy: 0.1740 - val_loss: 3.6040 - val_accuracy: 0.1300\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.8254 - accuracy: 0.1940 - val_loss: 3.5875 - val_accuracy: 0.1330\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.8937 - accuracy: 0.1735 - val_loss: 3.5838 - val_accuracy: 0.1360\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.8357 - accuracy: 0.2090 - val_loss: 3.5685 - val_accuracy: 0.1420\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.8278 - accuracy: 0.1900 - val_loss: 3.5913 - val_accuracy: 0.1400\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.7981 - accuracy: 0.1975 - val_loss: 3.5879 - val_accuracy: 0.1440\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.7743 - accuracy: 0.2075 - val_loss: 3.5653 - val_accuracy: 0.1560\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.7890 - accuracy: 0.2050 - val_loss: 3.5675 - val_accuracy: 0.1510\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.7571 - accuracy: 0.2105 - val_loss: 3.5795 - val_accuracy: 0.1460\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.7030 - accuracy: 0.2190 - val_loss: 3.5901 - val_accuracy: 0.1610\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.6685 - accuracy: 0.2205 - val_loss: 3.5602 - val_accuracy: 0.1620\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.6816 - accuracy: 0.2140 - val_loss: 3.5744 - val_accuracy: 0.1630\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.6300 - accuracy: 0.2445 - val_loss: 3.5681 - val_accuracy: 0.1610\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.6306 - accuracy: 0.2425 - val_loss: 3.5833 - val_accuracy: 0.1620\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.6808 - accuracy: 0.2310 - val_loss: 3.5834 - val_accuracy: 0.1610\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.5543 - accuracy: 0.2485 - val_loss: 3.5669 - val_accuracy: 0.1640\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.5373 - accuracy: 0.2610 - val_loss: 3.5793 - val_accuracy: 0.1730\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.5582 - accuracy: 0.2740 - val_loss: 3.5697 - val_accuracy: 0.1730\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.5134 - accuracy: 0.2720 - val_loss: 3.5875 - val_accuracy: 0.1760\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.4756 - accuracy: 0.2805 - val_loss: 3.6046 - val_accuracy: 0.1740\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.4426 - accuracy: 0.2825 - val_loss: 3.5918 - val_accuracy: 0.1810\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.4260 - accuracy: 0.2865 - val_loss: 3.6176 - val_accuracy: 0.1780\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.3982 - accuracy: 0.2960 - val_loss: 3.5925 - val_accuracy: 0.1810\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.4186 - accuracy: 0.2990 - val_loss: 3.6086 - val_accuracy: 0.1870\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.3878 - accuracy: 0.3170 - val_loss: 3.5950 - val_accuracy: 0.1880\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.3719 - accuracy: 0.3145 - val_loss: 3.6002 - val_accuracy: 0.1870\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.3139 - accuracy: 0.3290 - val_loss: 3.6310 - val_accuracy: 0.1860\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.2842 - accuracy: 0.3435 - val_loss: 3.6516 - val_accuracy: 0.1870\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.2890 - accuracy: 0.3445 - val_loss: 3.6064 - val_accuracy: 0.1900\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.2603 - accuracy: 0.3280 - val_loss: 3.6092 - val_accuracy: 0.1900\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.2825 - accuracy: 0.3245 - val_loss: 3.6278 - val_accuracy: 0.1930\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.2396 - accuracy: 0.3390 - val_loss: 3.6425 - val_accuracy: 0.1940\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.2113 - accuracy: 0.3590 - val_loss: 3.6750 - val_accuracy: 0.1980\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.2241 - accuracy: 0.3590 - val_loss: 3.6494 - val_accuracy: 0.1970\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.2102 - accuracy: 0.3595 - val_loss: 3.6119 - val_accuracy: 0.2000\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.2058 - accuracy: 0.3640 - val_loss: 3.6383 - val_accuracy: 0.2000\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.1605 - accuracy: 0.3685 - val_loss: 3.6514 - val_accuracy: 0.2070\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.0941 - accuracy: 0.3800 - val_loss: 3.6438 - val_accuracy: 0.2040\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.0931 - accuracy: 0.3875 - val_loss: 3.6682 - val_accuracy: 0.2000\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.0849 - accuracy: 0.3755 - val_loss: 3.6650 - val_accuracy: 0.2090\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.0946 - accuracy: 0.3860 - val_loss: 3.6715 - val_accuracy: 0.2040\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.0213 - accuracy: 0.3955 - val_loss: 3.6978 - val_accuracy: 0.2070\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.0321 - accuracy: 0.4115 - val_loss: 3.6703 - val_accuracy: 0.2080\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.0174 - accuracy: 0.3955 - val_loss: 3.6951 - val_accuracy: 0.2170\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.9823 - accuracy: 0.4210 - val_loss: 3.6996 - val_accuracy: 0.2200\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 2.0130 - accuracy: 0.3970 - val_loss: 3.6698 - val_accuracy: 0.2140\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.9699 - accuracy: 0.4225 - val_loss: 3.6567 - val_accuracy: 0.2250\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.9781 - accuracy: 0.4330 - val_loss: 3.6947 - val_accuracy: 0.2100\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.9014 - accuracy: 0.4330 - val_loss: 3.7380 - val_accuracy: 0.2180\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.9138 - accuracy: 0.4370 - val_loss: 3.7472 - val_accuracy: 0.2150\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.8916 - accuracy: 0.4345 - val_loss: 3.7164 - val_accuracy: 0.2220\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.8965 - accuracy: 0.4450 - val_loss: 3.7223 - val_accuracy: 0.2250\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.8742 - accuracy: 0.4325 - val_loss: 3.7275 - val_accuracy: 0.2290\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.8671 - accuracy: 0.4550 - val_loss: 3.7493 - val_accuracy: 0.2240\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.8160 - accuracy: 0.4570 - val_loss: 3.7472 - val_accuracy: 0.2250\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.8136 - accuracy: 0.4705 - val_loss: 3.7265 - val_accuracy: 0.2330\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.7770 - accuracy: 0.4560 - val_loss: 3.7470 - val_accuracy: 0.2390\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.8093 - accuracy: 0.4555 - val_loss: 3.7397 - val_accuracy: 0.2370\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.7827 - accuracy: 0.4820 - val_loss: 3.7626 - val_accuracy: 0.2330\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.8030 - accuracy: 0.4575 - val_loss: 3.7455 - val_accuracy: 0.2360\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.7527 - accuracy: 0.4850 - val_loss: 3.7581 - val_accuracy: 0.2340\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.7551 - accuracy: 0.4875 - val_loss: 3.7889 - val_accuracy: 0.2310\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.7031 - accuracy: 0.4920 - val_loss: 3.7983 - val_accuracy: 0.2390\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.7436 - accuracy: 0.4760 - val_loss: 3.8027 - val_accuracy: 0.2360\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.7264 - accuracy: 0.4755 - val_loss: 3.7923 - val_accuracy: 0.2330\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.6621 - accuracy: 0.5065 - val_loss: 3.8107 - val_accuracy: 0.2360\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.6980 - accuracy: 0.5035 - val_loss: 3.7926 - val_accuracy: 0.2380\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.6165 - accuracy: 0.5195 - val_loss: 3.8375 - val_accuracy: 0.2380\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.5661 - accuracy: 0.5315 - val_loss: 3.8527 - val_accuracy: 0.2350\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.6180 - accuracy: 0.5260 - val_loss: 3.8459 - val_accuracy: 0.2400\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.6461 - accuracy: 0.5140 - val_loss: 3.8942 - val_accuracy: 0.2280\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.6122 - accuracy: 0.5120 - val_loss: 3.8886 - val_accuracy: 0.2340\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.5799 - accuracy: 0.5415 - val_loss: 3.8477 - val_accuracy: 0.2350\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.5740 - accuracy: 0.5285 - val_loss: 3.8535 - val_accuracy: 0.2380\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.5346 - accuracy: 0.5470 - val_loss: 3.9092 - val_accuracy: 0.2300\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.5312 - accuracy: 0.5425 - val_loss: 3.8831 - val_accuracy: 0.2470\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.5206 - accuracy: 0.5475 - val_loss: 3.9050 - val_accuracy: 0.2370\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.5493 - accuracy: 0.5490 - val_loss: 3.8798 - val_accuracy: 0.2460\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.4914 - accuracy: 0.5650 - val_loss: 3.9045 - val_accuracy: 0.2460\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.4902 - accuracy: 0.5540 - val_loss: 3.9091 - val_accuracy: 0.2560\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.4755 - accuracy: 0.5610 - val_loss: 3.8839 - val_accuracy: 0.2550\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.4420 - accuracy: 0.5785 - val_loss: 3.9110 - val_accuracy: 0.2500\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.4574 - accuracy: 0.5725 - val_loss: 3.8894 - val_accuracy: 0.2530\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.4856 - accuracy: 0.5725 - val_loss: 3.9235 - val_accuracy: 0.2620\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.4034 - accuracy: 0.5815 - val_loss: 3.9671 - val_accuracy: 0.2510\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.4336 - accuracy: 0.5700 - val_loss: 3.9516 - val_accuracy: 0.2490\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3958 - accuracy: 0.5915 - val_loss: 3.9959 - val_accuracy: 0.2430\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3972 - accuracy: 0.5875 - val_loss: 3.9442 - val_accuracy: 0.2560\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3730 - accuracy: 0.5895 - val_loss: 3.9762 - val_accuracy: 0.2520\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.4097 - accuracy: 0.5815 - val_loss: 4.0063 - val_accuracy: 0.2470\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3336 - accuracy: 0.6115 - val_loss: 4.0012 - val_accuracy: 0.2460\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3409 - accuracy: 0.6095 - val_loss: 3.9718 - val_accuracy: 0.2530\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3717 - accuracy: 0.5885 - val_loss: 3.9557 - val_accuracy: 0.2550\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3534 - accuracy: 0.6060 - val_loss: 3.9731 - val_accuracy: 0.2610\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3146 - accuracy: 0.6045 - val_loss: 3.9919 - val_accuracy: 0.2610\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.2962 - accuracy: 0.6165 - val_loss: 4.0295 - val_accuracy: 0.2550\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3083 - accuracy: 0.6060 - val_loss: 4.0187 - val_accuracy: 0.2600\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.3216 - accuracy: 0.6110 - val_loss: 4.0098 - val_accuracy: 0.2570\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.2469 - accuracy: 0.6350 - val_loss: 4.0247 - val_accuracy: 0.2570\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.2322 - accuracy: 0.6340 - val_loss: 4.0616 - val_accuracy: 0.2600\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.2792 - accuracy: 0.6205 - val_loss: 4.0670 - val_accuracy: 0.2600\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.2333 - accuracy: 0.6405 - val_loss: 4.0548 - val_accuracy: 0.2670\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1859 - accuracy: 0.6465 - val_loss: 4.0985 - val_accuracy: 0.2680\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1942 - accuracy: 0.6435 - val_loss: 4.1000 - val_accuracy: 0.2670\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1678 - accuracy: 0.6610 - val_loss: 4.1227 - val_accuracy: 0.2650\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1906 - accuracy: 0.6395 - val_loss: 4.1058 - val_accuracy: 0.2680\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1680 - accuracy: 0.6660 - val_loss: 4.1695 - val_accuracy: 0.2650\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1967 - accuracy: 0.6595 - val_loss: 4.1461 - val_accuracy: 0.2700\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1888 - accuracy: 0.6495 - val_loss: 4.1114 - val_accuracy: 0.2710\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1020 - accuracy: 0.6630 - val_loss: 4.1258 - val_accuracy: 0.2650\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1291 - accuracy: 0.6540 - val_loss: 4.1424 - val_accuracy: 0.2730\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1023 - accuracy: 0.6795 - val_loss: 4.1806 - val_accuracy: 0.2720\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0976 - accuracy: 0.6660 - val_loss: 4.1713 - val_accuracy: 0.2800\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0428 - accuracy: 0.6960 - val_loss: 4.2084 - val_accuracy: 0.2730\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1147 - accuracy: 0.6755 - val_loss: 4.2535 - val_accuracy: 0.2730\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.1150 - accuracy: 0.6575 - val_loss: 4.2209 - val_accuracy: 0.2740\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0889 - accuracy: 0.6800 - val_loss: 4.2221 - val_accuracy: 0.2730\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0318 - accuracy: 0.6985 - val_loss: 4.2268 - val_accuracy: 0.2760\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0581 - accuracy: 0.6975 - val_loss: 4.2578 - val_accuracy: 0.2710\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0531 - accuracy: 0.6860 - val_loss: 4.2690 - val_accuracy: 0.2700\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0056 - accuracy: 0.7020 - val_loss: 4.2522 - val_accuracy: 0.2710\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0785 - accuracy: 0.6830 - val_loss: 4.2418 - val_accuracy: 0.2730\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0168 - accuracy: 0.6970 - val_loss: 4.2322 - val_accuracy: 0.2740\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0357 - accuracy: 0.6900 - val_loss: 4.2323 - val_accuracy: 0.2670\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 1.0267 - accuracy: 0.6860 - val_loss: 4.2519 - val_accuracy: 0.2800\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9370 - accuracy: 0.7195 - val_loss: 4.2721 - val_accuracy: 0.2830\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9896 - accuracy: 0.6940 - val_loss: 4.2719 - val_accuracy: 0.2780\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9790 - accuracy: 0.7100 - val_loss: 4.2921 - val_accuracy: 0.2830\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9800 - accuracy: 0.7055 - val_loss: 4.3064 - val_accuracy: 0.2860\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9694 - accuracy: 0.7140 - val_loss: 4.3267 - val_accuracy: 0.2780\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9238 - accuracy: 0.7295 - val_loss: 4.3464 - val_accuracy: 0.2860\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9375 - accuracy: 0.7265 - val_loss: 4.3909 - val_accuracy: 0.2820\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9415 - accuracy: 0.7210 - val_loss: 4.3323 - val_accuracy: 0.2810\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9159 - accuracy: 0.7310 - val_loss: 4.3698 - val_accuracy: 0.2820\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9417 - accuracy: 0.7210 - val_loss: 4.3577 - val_accuracy: 0.2780\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9783 - accuracy: 0.7140 - val_loss: 4.3284 - val_accuracy: 0.2840\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9021 - accuracy: 0.7225 - val_loss: 4.3483 - val_accuracy: 0.2850\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.8642 - accuracy: 0.7390 - val_loss: 4.2995 - val_accuracy: 0.2900\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.8922 - accuracy: 0.7380 - val_loss: 4.3433 - val_accuracy: 0.2810\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.8786 - accuracy: 0.7375 - val_loss: 4.4073 - val_accuracy: 0.2820\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.9039 - accuracy: 0.7320 - val_loss: 4.3661 - val_accuracy: 0.2820\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.8465 - accuracy: 0.7465 - val_loss: 4.3592 - val_accuracy: 0.2830\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.8742 - accuracy: 0.7400 - val_loss: 4.3797 - val_accuracy: 0.2860\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.8242 - accuracy: 0.7535 - val_loss: 4.4096 - val_accuracy: 0.2860\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.8835 - accuracy: 0.7365 - val_loss: 4.3877 - val_accuracy: 0.2920\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.8468 - accuracy: 0.7450 - val_loss: 4.4178 - val_accuracy: 0.2930\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.7888 - accuracy: 0.7615 - val_loss: 4.4156 - val_accuracy: 0.2910\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(learning_rate = 0.00001, beta_1=0.9, beta_2=0.999)\n",
    "combined_model.compile(optimizer= adam,loss=lambda y_true,y_pred: LWF_loss(y_true, y_pred,lambd=0.8,T=10),metrics=['accuracy'])\n",
    "history = combined_model.fit(trainX,new_train_y,epochs=200,validation_data=(testX,new_test_y),batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plothist_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plothist_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 402us/sample - loss: 2.6580 - accuracy: 0.2910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.4156144971847535, 0.291]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.evaluate(testX,new_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 34, 34, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   1792        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 34, 34, 64)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   36928       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 16, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 18, 18, 64)   0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 128)  73856       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 18, 18, 128)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 128)  147584      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 10, 10, 128)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 256)    295168      zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 256)    1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 256)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 10, 10, 256)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 256)    590080      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 256)    1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 10, 10, 256)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 256)    590080      zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 6, 6, 256)    0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 512)    1180160     zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4, 4, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 6, 6, 512)    0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 512)    2359808     zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 4, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 6, 6, 512)    0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 512)    2359808     zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 4, 4, 512)    0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 2, 2, 512)    2359808     zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 512)    2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 2, 2, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 4, 4, 512)    0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 512)    2359808     zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2, 2, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 2, 2, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 4, 4, 512)    0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 512)    2359808     zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2, 2, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         2101248     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4096)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         16781312    dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 4096)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 100)          409700      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           40970       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "old_activation (Activation)     (None, 10)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 110)          0           activation_1[0][0]               \n",
      "                                                                 old_activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 34,064,814\n",
      "Trainable params: 34,015,396\n",
      "Non-trainable params: 49,418\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 34, 34, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 33,655,114\n",
      "Trainable params: 40,970\n",
      "Non-trainable params: 33,614,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "oldModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 48s 968us/sample - loss: 0.9717 - accuracy: 0.6903 - val_loss: 1.3378 - val_accuracy: 0.6838\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.7201 - accuracy: 0.7720 - val_loss: 1.3902 - val_accuracy: 0.6881\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.7099 - accuracy: 0.7758 - val_loss: 1.4032 - val_accuracy: 0.6909\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 47s 944us/sample - loss: 0.6956 - accuracy: 0.7770 - val_loss: 1.3833 - val_accuracy: 0.6937\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 47s 942us/sample - loss: 0.6877 - accuracy: 0.7789 - val_loss: 1.4187 - val_accuracy: 0.6909\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.6925 - accuracy: 0.7777 - val_loss: 1.4087 - val_accuracy: 0.6936\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 47s 941us/sample - loss: 0.6709 - accuracy: 0.7850 - val_loss: 1.4317 - val_accuracy: 0.6929\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.6803 - accuracy: 0.7828 - val_loss: 1.4286 - val_accuracy: 0.6921\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.6700 - accuracy: 0.7840 - val_loss: 1.4450 - val_accuracy: 0.6922\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 47s 944us/sample - loss: 0.6706 - accuracy: 0.7845 - val_loss: 1.4084 - val_accuracy: 0.6963\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 47s 942us/sample - loss: 0.6691 - accuracy: 0.7841 - val_loss: 1.4084 - val_accuracy: 0.6949\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 47s 944us/sample - loss: 0.6614 - accuracy: 0.7855 - val_loss: 1.3658 - val_accuracy: 0.7002\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 47s 942us/sample - loss: 0.6590 - accuracy: 0.7861 - val_loss: 1.4252 - val_accuracy: 0.6952\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.6496 - accuracy: 0.7885 - val_loss: 1.3838 - val_accuracy: 0.6985\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 47s 942us/sample - loss: 0.6549 - accuracy: 0.7845 - val_loss: 1.4050 - val_accuracy: 0.6967\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 47s 944us/sample - loss: 0.6543 - accuracy: 0.7864 - val_loss: 1.3755 - val_accuracy: 0.6994\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 47s 942us/sample - loss: 0.6515 - accuracy: 0.7881 - val_loss: 1.4233 - val_accuracy: 0.6952\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.6408 - accuracy: 0.7900 - val_loss: 1.4039 - val_accuracy: 0.6973\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 47s 942us/sample - loss: 0.6478 - accuracy: 0.7874 - val_loss: 1.3598 - val_accuracy: 0.6994\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.6365 - accuracy: 0.7929 - val_loss: 1.4033 - val_accuracy: 0.6967\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 47s 944us/sample - loss: 0.6380 - accuracy: 0.7910 - val_loss: 1.3838 - val_accuracy: 0.6991\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.6395 - accuracy: 0.7902 - val_loss: 1.4083 - val_accuracy: 0.6961\n"
     ]
    }
   ],
   "source": [
    "oldOutput = keras.Model(combined_model.input,combined_model.layers[-6].output)\n",
    "oldOutput.trainable=False\n",
    "DenseL = Dense(10,name='dense_10')(oldOutput.output)\n",
    "SoftmaxLayer = Activation('softmax')(DenseL)\n",
    "oldModel = keras.Model(oldOutput.input,SoftmaxLayer)\n",
    "adam = Adam(learning_rate = 0.00001, beta_1=0.9, beta_2=0.999)\n",
    "oldModel.compile(optimizer= adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',patience=10,mode='auto',restore_best_weights=True)\n",
    "history = oldModel.fit(train_x,train_y,epochs=200,validation_data=(test_x,test_y),callbacks=[early_stopping],batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
